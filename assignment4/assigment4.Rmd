---
title: "PoCS Assignment 4"
author: "P. Alexander Burnham"
date: "September 25, 2018"
output: pdf_document
---
PoCS Assignment github repo: https://github.com/alexburn17/BurnhamPoCS


Worked with: Yu Han, Edison & Kewang



**Problem 1:**

```{r, echo=FALSE, message=FALSE}

# START FUNCTION ###########################################################################

SimonMod <- function(p=0.01, bag=bagVec, runTime=100){

vec <- bag[runif(n=1, 1, length(bag))]
  
for(i in 1:runTime){

  pact <- runif(1)
  
  if(pact<=p){ 
    vec[i] <- bag[runif(n=1, 1, length(bag))]}
  
  if(pact>p){ 
    vec[i] <- vec[runif(n=1, 1, length(vec))]}
}
  return(vec)
}

# END FUNCTION #############################################################################



par(mfrow=c(1,3))

bagVec <- c(0:1000000)

# p=0.1
SimonVec.1 <- SimonMod(p=0.1, bag=bagVec, runTime=1000000)

x <- as.data.frame(table(SimonVec.1))
x$Freq<- log10(x$Freq)
x <- x[order(x$Freq, decreasing = T),] 

mod <- lm(x$Freq~log10(1:length(x$Freq)))

plot(y=x$Freq, x=log10(1:length(x$Freq)), main="Simon Zipf plot (p=0.1)", 
     ylab="log10(Frequency)", xlab = "log10(Rank)")
abline(mod, col="green")
text(x=2,y=5, paste("slope=",round(mod$coefficients[2], 3)))


# p=0.01
SimonVec.01 <- SimonMod(p=0.01, bag=bagVec, runTime=1000000)

x1 <- as.data.frame(table(SimonVec.01))
x1$Freq<- log10(x1$Freq)
x1 <- x1[order(x1$Freq, decreasing = T),] 

mod1 <- lm(x1$Freq~log10(1:length(x1$Freq)))

plot(y=x1$Freq, x=log10(1:length(x1$Freq)), main="Simon Zipf plot (p=0.01)", 
     ylab="log10(Frequency)", xlab = "log10(Rank)")
abline(mod1, col="red")
text(x=2,y=5, paste("slope=",round(mod1$coefficients[2], 3)))

# p=0.001
SimonVec.001 <- SimonMod(p=0.001, bag=bagVec, runTime=10000000)

x2 <- as.data.frame(table(SimonVec.001))
x2$Freq<- log10(x2$Freq)
x2 <- x2[order(x2$Freq, decreasing = T),] 

mod2 <- lm(x2$Freq~log10(1:length(x2$Freq)))

plot(y=x2$Freq, x=log10(1:length(x2$Freq)), main="Simon Zipf plot (p=0.001)", 
     ylab="log10(Frequency)", xlab = "log10(Rank)")
abline(mod2, col="blue")
text(x=2,y=5, paste("slope=",round(mod2$coefficients[2], 3)))

par(mfrow=c(1,1))



```
The slopes would be closer to the expexted values of 0.9, 0.99 and 0.999 if they were repeated more times and the distributions were trimmed before the regressions were conducted, however, they are very close and we see an increase in the value as $\rho$ decreases.


**Problem 2:**




**a)**

Given: $\frac{n_k}{n_{k+1}}=\frac{(k-1)(1-\rho)}{1+(1-\rho)k}$, $z=(1-\rho)$, $n_1=\frac{\rho}{2-\rho}$

Gamma Function says: $\Gamma(k)=(k-1)!$

From Video:

Step 1: write difference equation for an idea of what is going on 

$$n_k=\Bigg[ \frac{(k-1)(1-\rho)}{1+(1-\rho)k}\Bigg]$$

$$n_{k-1}=\Bigg[ \frac{(k-2)(1-\rho)}{1+(1-\rho)(k-1)}\Bigg]$$

$$n_{k-2}=\Bigg[ \frac{(k-3)(1-\rho)}{1+(1-\rho)(k-2)}\Bigg]$$

etc.

Step 2: Denominator sub in $z$ for $1-\rho$

$$[(1+zk)(1+zk-1)(1+z)(k-2)…(1+2z)(1+z)]\frac{1}{1+z}$$

simplify...

$$z^k(\frac{1}{z}+k)(\frac{1}{z}+k-1)...(\frac{1}{z}+1)(\frac{1}{1+z})$$

$$Denominator=\frac{z^k\Gamma(\frac{1}{z}+k-1)}{\Gamma(\frac{1}{z}+1)}*\frac{1}{1+z}$$



Step 3: Numerator sub in $z$ for $1-\rho$ and $\Gamma(k)$ for $(k-1)!$

$$=(k-1)(1-\rho)(k-2)(1-\rho)(k-3)(1-\rho)…(1-\rho)$$

simplify...

$$=(1-\rho)^{(k-1)}(k-1)!$$

$$=z^{(k-1)}\Gamma(k)$$

Step 4: put numerator of denominator, multiply by $n_1$ and simplify 

$$=\frac{z^{(k-1)}\Gamma(k)}{\frac{z^k\Gamma(\frac{1}{z}+k-1)}{\Gamma(\frac{1}{z}+1)}*\frac{1}{1+z}}*\frac{\rho}{2-\rho}$$

cross out $z^k$ and move $z^{-1}$ to denominator sub in: $\rho=1-z$

$$=\frac{\Gamma(k)}{z\frac{\Gamma(\frac{1}{z}+k-1)}{\Gamma(\frac{1}{z}+1)}*\frac{1}{1+z}}*\frac{(1-z)}{2-(1-z)}$$

$$=\frac{\Gamma(k)}{z}(1+z)\frac{\Gamma(\frac{1}{z}+1)}{\Gamma(\frac{1}{z}+k-1)}*\frac{(1-z)}{2-(1-z)}$$

simplify and sub $\rho$ back in:

$$=\frac{\Gamma(k)\Gamma(\frac{1}{z}+1)}{\Gamma(\frac{1}{z}+k-1)}*\frac{\rho}{1-\rho}$$

Use beta function to derive: 

$$\beta(x,y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)} =\frac{(x-1)!(y-1)!}{(x+y-1)!}$$

$$n_k=\frac{\rho}{1-\rho}*\beta(k,\frac{1}{1-\rho}+1)$$


**b)**


$$n_k=\frac{\rho}{1-\rho}*\beta(k,\frac{1}{1-\rho}+1)$$

use the fact that $\beta(k,\gamma) = k^{-\gamma}$

$$n_k=\frac{\rho}{1-\rho}*k^{-(\frac{1}{1-\rho}+1)}$$

$$\gamma=\frac{1}{1-\rho}+1$$

$$\gamma=\frac{2-\rho}{1-\rho}$$


**Problem 3:**

$$\lim_{\gamma \to 0} \gamma=\frac{2-\rho}{1-\rho}$$


As $\rho$ approaches $0$, $\gamma$ goes to $2$.


$$\lim_{\gamma \to 1} \gamma=\frac{2-\rho}{1-\rho}$$

As $\rho$ approaches $1$, $\gamma$ goes to $\infty$.


**Problem 4:**



**a)**

Given:

$n_1^{(g)} = \frac{N_1t}{\rho t} = \frac{1}{2-\rho}$ & $\frac{n_k}{n_{k+1}}=\frac{(k-1)(1-\rho)}{1+(1-\rho)k}$ 

Step 1: Set up to find $n_1^{(g)}$ and plug in $k=2$ and multiply by $n_1^{(g)}$

$$\frac{n_2^{(g)}}{n_1^{(g)}}=\frac{\frac{N_2}{\rho}}{\frac{N_1}{\rho}}=\frac{N_2}{N_1}=\frac{(2-1)(1-\rho)}{1+(1-\rho)2}*n_1^{(g)}$$ 

$$n_2^{(g)}=\frac{(2-1)(1-\rho)}{1+(1-\rho)2}* \frac{1}{2-\rho}$$

$$n_2^{(g)}=\frac{(1-\rho)}{3-2\rho}* \frac{1}{2-\rho}$$



Step 2: find $n_3^{(g)}$ in the same way

$$\frac{n_3^{(g)}}{n_2^{(g)}}=\frac{\frac{N_3}{\rho}}{\frac{N_2}{\rho}}=\frac{N_3}{N_2}=\frac{(3-1)(1-\rho)}{1+(1-\rho)3}*n_2^{(g)}$$ 

$$n_3^{(g)}=\frac{2-2\rho}{4-3\rho}*\frac{(1-\rho)}{3-2\rho}* \frac{1}{2-\rho}$$



**b)**



```{r, echo=FALSE, message=FALSE}

par(mfrow=c(1,2))
setwd("~/Documents/GitHub/BurnhamPoCS/assignment4")

# Read in Data:
book <- read.csv("book.csv", 
                header=TRUE, 
                stringsAsFactors = FALSE)
x3 <- log10(book$X41)

x3 <- x3[order(x3, decreasing = T)]

mod3 <- lm(x3~log10(1:length(x3)))

plot(x3, x=log10(1:length(x3)), main = "Zipf Plot of Ulysses", ylab="log10(Frequency)", xlab="log10(Rank)")

abline(mod3, col="red")
text(x=3, y=3.5, paste("slope: -1.012"))



x4 <- x3[x3<2.9 & x3 > 1]

mod4 <- lm(x4~log10(1:length(x4)))

plot(x4, x=log10(1:length(x4)), main = "Zipf Plot of Ulysses (Trimmed)", ylab="log10(Frequency)", xlab="log10(Rank)", xlim=c(1.5,3.5))

abline(mod4, col="red")
text(x=3, y=2.5, paste("a = 0.8715"))
text(x=3, y=2.1, paste("p = 0.1285"))

#alpha = 1 - p

#0.8715 = 1 - p

par(mfrow=c(1,1))
```


The estimate of $\rho$ was 0.1285 based on a trimmed distribution to increase accuracy.

Plugging this value in for $n_1^{(g)}, n_2^{(g)}, n_3^{(g)}$ gives the theoretical estimates. The actual values are found by taking the number of groups with frequencies of 1, 2 and 3 in turn over the total number of groups. This gives the following values:

Actual (measured from data set):

- $n_1^{(g)} = 0.565$
- $n_2^{(g)} = 0.156$
- $n_2^{(g)} = 0.071$

Theoretical (using estimate for $\rho$:

- $n_1^{(g)} = 0.534$

- $n_2^{(g)} = 0.1697$

- $n_2^{(g)} = 0.082$

These values are all very simaler meaning that our estimate matches our theoretical values well.

**c)**

```{r, echo=FALSE, message=FALSE}
one <- book[book$X41==1,]
#length(one$X0)/length(book$X0)

two <- book[book$X41==2,]
#length(two$X0)/length(book$X0)


three <- book[book$X41==3,]
#length(three$X0)/length(book$X0)
```



**Problem 5:**



**a)**





Given: $P_k=ck^{-\gamma}$

Step 1: find c

$$\int_{k_{min}}^{\infty} ck^{-\gamma}=1$$

$$c\frac{1}{-\gamma+1}k^{(-\gamma+1)}|^{\infty}_{k_{min}}=1$$

$$c\frac{1}{\gamma-1}k_{min}^{(-\gamma+1)}=1$$

find c:

$$c=(\gamma-1)k_{min}^{(\gamma-1)}$$



Step 2: find $k_{max}$

$$\sum_{mink_{max}}^{\infty} ck^{-\gamma} = \frac{1}{N}$$

$$\int_{k_{max}}^{\infty} ck^{-\gamma}=\frac{1}{N}$$

$$\int_{k_{max}}^{\infty} k^{-\gamma}=\frac{1}{cN}$$

Find antiderivative 

$$\frac{1}{\gamma-1}k_{max}^{-\gamma+1}=\frac{1}{cN}$$

multiply both sides by $(\gamma-1)$

$$k_{max}^{-\gamma+1}=\frac{\gamma-1}{cN}$$



$$k_{max}=\Big( \frac{\gamma-1}{c} \Big)^{(\frac{1}{1-\gamma})}\frac{1}{N}^{(\frac{1}{1-\gamma})}$$

Step 3: sub in C and simplify:

 $$k_{max}=\Big( \frac{\gamma-1}{(\gamma-1)k_{min}^{(\gamma-1)}} \Big)^{(\frac{1}{1-\gamma})}\frac{1}{N}^{(\frac{1}{1-\gamma})}$$

cancel terms:

 $$k_{max}=k_{min}\frac{1}{N^{(\frac{1}{1-\gamma})}}$$

Answer:

 $$k_{max}=k_{min}{N^{(\frac{1}{\gamma-1})}}$$





**b)**


Step 1:

$$=\int_{k_{max}}^{\infty} ck^{-\gamma+1}dk$$

antiderivative:

$$=c\frac{1}{2-\gamma}k^{2-\gamma}|^{\infty}_{k_{max}}$$

$$=c\frac{1}{\gamma-2}k_{max}^{2-\gamma}$$

plug in $c$ and $k_{max}$

$$=(\gamma-1)k_{min}^{(\gamma-1)}\frac{1}{\gamma-2}\Bigg(k_{min}\frac{1}{N^{(\frac{1}{1-\gamma})}}\Bigg)^{2-\gamma}$$

Step 2: simplify

$$\frac{\gamma-1}{\gamma-2}k_{min}^{(\gamma-1)}k_{min}^{(2-\gamma)}\frac{1}{N^{(\frac{2-\gamma}{1-\gamma})}}$$

$$k_{min}\frac{\gamma-1}{\gamma-2}*\frac{1}{N^{(\frac{2-\gamma}{1-\gamma})}}$$

$$k_{min}\frac{\gamma-1}{\gamma-2}*\mathbf{{N^{(\frac{2-\gamma}{\gamma-1})}}}$$




**Problem 6:**



**a)**



```{r, echo=FALSE, message=FALSE}

library("poweRlaw")

N=c(1, 10^2, 10^3, 10^4, 10^5, 10^6) 
k=(1:1000)


#mat <- matrix(nrow = 1000, ncol = 6)

#for(n in 1:6){
#  for(i in 1:1000){
#    mat[i, n] <- max(rpldis(n=N[n], xmin=1, alpha=5/2, discrete_max = 1000))
#}
#}


#matDat <- as.data.frame(mat)
#CD.sorted <- apply(matDat, 2, sort, decreasing=T)

setwd("~/Documents/GitHub/BurnhamPoCS/assignment4")

# Read in Data:
mat <- read.csv("NKsorted.csv", 
                header=TRUE, 
                stringsAsFactors = FALSE)

mat2 <- as.matrix(mat)

matplot(log10(mat2), type="o", cex=.2, main="K_max by N", xlab = "Rank", ylab="log10(k_max)", col=c(1:6))
legend("topright", inset=0.01, legend=c("10^1","10^2","10^3","10^4","10^5","10^6"), col=c(1:6), pch=15)

```



**b)**



```{r, echo=FALSE, message=FALSE}
par(mfrow=c(1,2))

kmeanEst <- colMeans(mat2)
mod5 <- lm(log10(kmeanEst)~log10(N)) 
plot(y=log10(kmeanEst), x=log10(N), main="K_max estimate by N", xlab = "log10(N)", ylab = "log10((k_max))")
abline(mod5, col="blue")
text(x=2,y=4, "slope = 0.6262")

gamma <- 5/2

kmeanTher <- ((gamma-1)/(gamma-2))*N^((2-gamma)/(gamma-1))

mod6 <- lm(log10(kmeanTher)~log10(N)) 
plot(y=log10(kmeanTher), x=log10(N), main="K_max theoretical by N", xlab = "log10(N)", ylab = "log10((k_max))")
abline(mod6, col="red")
text(x=3,y=.3, "slope = -0.3333")
par(mfrow=c(1,1))
```

My theoretical value and empirical values do no match up. The one I calculated by sampling a powerlaw distribution has a positive slope of around 0.6. This makes sense as the max k should increase as the sample size increases. However, my derivation of the theoretical max k has a negative slope of -0.3. This does no make sense and leads me to believe that my model is correct and the theoretical values are incorrect. $K_max$ should increase as N increases as this increase in N gives higher probability of capturing a large $K$. The theretical value looks like it is flipped about the y axis as the spacing of the points is simaler.